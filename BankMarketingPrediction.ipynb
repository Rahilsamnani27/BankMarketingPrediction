{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce169b-b1bb-419e-b8bf-ff8adea52a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR, DT, NB, XGBOOST Modeling - Bank Marketing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f4a75c0-8bd3-4545-9ea3-d34ed8e9104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "204e36d8-64c9-48db-8ad7-6fcf8d0003ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Preprocessed data. First column is deleted because its index and redundant\n",
    "df=pd.read_csv(\"PreprocessedBank.csv\").drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad13448a-8a2d-4f46-a7c5-797a985a0e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>...</th>\n",
       "      <th>jun</th>\n",
       "      <th>mar</th>\n",
       "      <th>may</th>\n",
       "      <th>nov</th>\n",
       "      <th>oct</th>\n",
       "      <th>sep</th>\n",
       "      <th>failure</th>\n",
       "      <th>success</th>\n",
       "      <th>unknown</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>2476</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  balance  housing  loan  day  duration  campaign  pdays  \\\n",
       "0   59        1     2343        0     1    5      1042         1     -1   \n",
       "1   56        1       45        1     1    5      1467         1     -1   \n",
       "2   41        1     1270        0     1    5      1389         1     -1   \n",
       "3   55        1     2476        0     1    5       579         1     -1   \n",
       "4   54        1      184        1     1    5       673         2     -1   \n",
       "\n",
       "   previous  ...  jun  mar  may  nov  oct  sep  failure  success  unknown  \\\n",
       "0         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "1         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "2         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "3         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "4         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "\n",
       "   deposit  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c88d1461-99d4-4e7f-9ed7-1a595b3aa7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>...</th>\n",
       "      <th>jul</th>\n",
       "      <th>jun</th>\n",
       "      <th>mar</th>\n",
       "      <th>may</th>\n",
       "      <th>nov</th>\n",
       "      <th>oct</th>\n",
       "      <th>sep</th>\n",
       "      <th>failure</th>\n",
       "      <th>success</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.491505</td>\n",
       "      <td>0.123617</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>-1.055280</td>\n",
       "      <td>0.387923</td>\n",
       "      <td>-1.265746</td>\n",
       "      <td>1.930226</td>\n",
       "      <td>-0.554168</td>\n",
       "      <td>-0.481184</td>\n",
       "      <td>-0.36326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396136</td>\n",
       "      <td>-0.350625</td>\n",
       "      <td>-0.159228</td>\n",
       "      <td>1.718298</td>\n",
       "      <td>-0.303775</td>\n",
       "      <td>-0.190781</td>\n",
       "      <td>-0.171522</td>\n",
       "      <td>-0.35159</td>\n",
       "      <td>-0.325782</td>\n",
       "      <td>0.583626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.239676</td>\n",
       "      <td>0.123617</td>\n",
       "      <td>-0.459974</td>\n",
       "      <td>0.947616</td>\n",
       "      <td>0.387923</td>\n",
       "      <td>-1.265746</td>\n",
       "      <td>3.154612</td>\n",
       "      <td>-0.554168</td>\n",
       "      <td>-0.481184</td>\n",
       "      <td>-0.36326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396136</td>\n",
       "      <td>-0.350625</td>\n",
       "      <td>-0.159228</td>\n",
       "      <td>1.718298</td>\n",
       "      <td>-0.303775</td>\n",
       "      <td>-0.190781</td>\n",
       "      <td>-0.171522</td>\n",
       "      <td>-0.35159</td>\n",
       "      <td>-0.325782</td>\n",
       "      <td>0.583626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.019470</td>\n",
       "      <td>0.123617</td>\n",
       "      <td>-0.080160</td>\n",
       "      <td>-1.055280</td>\n",
       "      <td>0.387923</td>\n",
       "      <td>-1.265746</td>\n",
       "      <td>2.929901</td>\n",
       "      <td>-0.554168</td>\n",
       "      <td>-0.481184</td>\n",
       "      <td>-0.36326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396136</td>\n",
       "      <td>-0.350625</td>\n",
       "      <td>-0.159228</td>\n",
       "      <td>1.718298</td>\n",
       "      <td>-0.303775</td>\n",
       "      <td>-0.190781</td>\n",
       "      <td>-0.171522</td>\n",
       "      <td>-0.35159</td>\n",
       "      <td>-0.325782</td>\n",
       "      <td>0.583626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.155733</td>\n",
       "      <td>0.123617</td>\n",
       "      <td>0.293762</td>\n",
       "      <td>-1.055280</td>\n",
       "      <td>0.387923</td>\n",
       "      <td>-1.265746</td>\n",
       "      <td>0.596366</td>\n",
       "      <td>-0.554168</td>\n",
       "      <td>-0.481184</td>\n",
       "      <td>-0.36326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396136</td>\n",
       "      <td>-0.350625</td>\n",
       "      <td>-0.159228</td>\n",
       "      <td>1.718298</td>\n",
       "      <td>-0.303775</td>\n",
       "      <td>-0.190781</td>\n",
       "      <td>-0.171522</td>\n",
       "      <td>-0.35159</td>\n",
       "      <td>-0.325782</td>\n",
       "      <td>0.583626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.071790</td>\n",
       "      <td>0.123617</td>\n",
       "      <td>-0.416876</td>\n",
       "      <td>0.947616</td>\n",
       "      <td>0.387923</td>\n",
       "      <td>-1.265746</td>\n",
       "      <td>0.867171</td>\n",
       "      <td>-0.186785</td>\n",
       "      <td>-0.481184</td>\n",
       "      <td>-0.36326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396136</td>\n",
       "      <td>-0.350625</td>\n",
       "      <td>-0.159228</td>\n",
       "      <td>1.718298</td>\n",
       "      <td>-0.303775</td>\n",
       "      <td>-0.190781</td>\n",
       "      <td>-0.171522</td>\n",
       "      <td>-0.35159</td>\n",
       "      <td>-0.325782</td>\n",
       "      <td>0.583626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age   default   balance   housing      loan       day  duration  \\\n",
       "0  1.491505  0.123617  0.252525 -1.055280  0.387923 -1.265746  1.930226   \n",
       "1  1.239676  0.123617 -0.459974  0.947616  0.387923 -1.265746  3.154612   \n",
       "2 -0.019470  0.123617 -0.080160 -1.055280  0.387923 -1.265746  2.929901   \n",
       "3  1.155733  0.123617  0.293762 -1.055280  0.387923 -1.265746  0.596366   \n",
       "4  1.071790  0.123617 -0.416876  0.947616  0.387923 -1.265746  0.867171   \n",
       "\n",
       "   campaign     pdays  previous  ...       jul       jun       mar       may  \\\n",
       "0 -0.554168 -0.481184  -0.36326  ... -0.396136 -0.350625 -0.159228  1.718298   \n",
       "1 -0.554168 -0.481184  -0.36326  ... -0.396136 -0.350625 -0.159228  1.718298   \n",
       "2 -0.554168 -0.481184  -0.36326  ... -0.396136 -0.350625 -0.159228  1.718298   \n",
       "3 -0.554168 -0.481184  -0.36326  ... -0.396136 -0.350625 -0.159228  1.718298   \n",
       "4 -0.186785 -0.481184  -0.36326  ... -0.396136 -0.350625 -0.159228  1.718298   \n",
       "\n",
       "        nov       oct       sep  failure   success   unknown  \n",
       "0 -0.303775 -0.190781 -0.171522 -0.35159 -0.325782  0.583626  \n",
       "1 -0.303775 -0.190781 -0.171522 -0.35159 -0.325782  0.583626  \n",
       "2 -0.303775 -0.190781 -0.171522 -0.35159 -0.325782  0.583626  \n",
       "3 -0.303775 -0.190781 -0.171522 -0.35159 -0.325782  0.583626  \n",
       "4 -0.303775 -0.190781 -0.171522 -0.35159 -0.325782  0.583626  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardisation of Data\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(df.drop('deposit',axis=1))\n",
    "scaled_features=scaler.transform(df.drop('deposit',axis=1))\n",
    "df_feat=pd.DataFrame(scaled_features,columns=df.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6346696-0ff4-4bf8-9442-178de64ee635",
   "metadata": {},
   "source": [
    "Notes :\n",
    "1. Algorithms like KNN, Naive Bayes, Logistic Regression and SVM require Standardised Data\n",
    "2. Tree-based Algorithms are scale independent\n",
    "3. Standardisation basically subtracts the mean and divides the std deviation of the column from each value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba9c38-b94c-461c-a77e-a0591b43a166",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1b74dcb-3eb4-485a-b4ea-9c5435249fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30% Data is set aside for tesing\n",
    "X_train,X_test,y_train,y_test=train_test_split(scaled_features,df['deposit'],test_size=0.30, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db1e0f-6c6e-484c-a0c0-337c54a52a68",
   "metadata": {},
   "source": [
    "# Applying Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9893057d-c3a5-4fce-be68-059f3c81ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1517  257]\n",
      " [ 737  838]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75      1774\n",
      "           1       0.77      0.53      0.63      1575\n",
      "\n",
      "    accuracy                           0.70      3349\n",
      "   macro avg       0.72      0.69      0.69      3349\n",
      "weighted avg       0.72      0.70      0.69      3349\n",
      "\n",
      "AUC score for NB is  0.7965192104650956\n",
      "Test Accuracy score for NB is  0.7031949835771872\n",
      "Train Accuracy score for NB is  0.7317291693331627\n",
      "Recall score for NB is  0.532063492063492\n"
     ]
    }
   ],
   "source": [
    "# Training Naive bayes\n",
    "# Finding Accuracy, AUC, False Positive Rate, True positive rate, confusion matrix and classificatio report\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "pred = gnb.predict(X_test)\n",
    "accNB = accuracy_score(y_test, pred)\n",
    "y_pred_prob = gnb.predict_proba(X_test)\n",
    "aucScoreNB = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprNB, tprNB, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"AUC score for NB is \",aucScoreNB)\n",
    "print(\"Test Accuracy score for NB is \",accuracy_score(y_test, pred))\n",
    "predT=gnb.predict(X_train)\n",
    "print(\"Train Accuracy score for NB is \",accuracy_score(y_train, predT))\n",
    "#print(\"Best parameters for NB are \",gnb.best_params_)\n",
    "print(\"Recall score for NB is \",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e97b2-3e0d-4d7a-acb2-fbe05837379a",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. Naive Bayes gives an accuracy of 0.70, which is not very good\n",
    "2. There is very little difference between train and test accuracy, so its not overfitting or underfitting\n",
    "3. Recall is 0.53, which is very poor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b012d5-082a-4833-b3cd-0875148f26b8",
   "metadata": {},
   "source": [
    "# Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3ac649d-afdf-4101-a5be-ef9640e79e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 10000]\n",
    "    }\n",
    "]\n",
    "logModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1bb830-8169-4925-ac54-3e484ce2720c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. Hyperparameters for Logistic Regression\n",
    "2. Penalty indicates which regularization to use\n",
    "3. C decides how much weightage is given to Regularization\n",
    "4. Solver is the technique used internally\n",
    "5. max_iter is the number of iterations for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adac8dfd-b28f-421a-b430-aeb0d60dc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridsearchCV tries all possible combinations of hyperparameters to find best accuracy\n",
    "\n",
    "clf = GridSearchCV(logModel, param_grid = param_grid,scoring='accuracy', cv = 5 )\n",
    "best_clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf6d9789-014b-426b-a371-62f1ac62138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1489  285]\n",
      " [ 322 1253]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1774\n",
      "           1       0.81      0.80      0.81      1575\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "AUC score for LR is  0.8913383797712997\n",
      "Test Accuracy score for LR is  0.818751866228725\n",
      "Train Accuracy score for LR is  0.8306668373224113\n",
      "Best parameters for accuracy of LR are  {'C': 0.615848211066026, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression\n",
    "# Finding Accuracy, AUC, False positive rate, True positive rate, confusion matrix and classificatio report\n",
    "\n",
    "pred = best_clf.predict(X_test)\n",
    "accLR = accuracy_score(y_test, pred)\n",
    "y_pred_prob = best_clf.predict_proba(X_test)\n",
    "aucScoreLR = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprLR, tprLR, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"AUC score for LR is \",aucScoreLR)\n",
    "print(\"Test Accuracy score for LR is \",accuracy_score(y_test, pred))\n",
    "predT=best_clf.predict(X_train)\n",
    "print(\"Train Accuracy score for LR is \",accuracy_score(y_train, predT))\n",
    "print(\"Best parameters for accuracy of LR are \",best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "987dd963-8530-48c4-a9f2-b4c4ec5d6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic Regression for recall\n",
    "\n",
    "clfR = GridSearchCV(logModel, param_grid = param_grid,scoring='recall', cv = 5 )\n",
    "best_clfR = clfR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "229a4268-17f8-4763-b298-da9c104d9f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall score for LR is  0.7949206349206349\n",
      "Train recall score for LR is  0.7977921378567582\n",
      "Best parameters for recall of LR are  {'C': 29.763514416313132, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# print recall and best parameters\n",
    "\n",
    "predR = best_clfR.predict(X_test)\n",
    "predRT=best_clfR.predict(X_train)\n",
    "recallLR=recall_score(y_test, predR)\n",
    "print(\"Test Recall score for LR is \",recallLR)\n",
    "print(\"Train recall score for LR is \",recall_score(y_train, predRT))\n",
    "print(\"Best parameters for recall of LR are \",best_clfR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce93a6-267f-4d46-8791-3b1e43c7dc99",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. Logistic Regression gives accuracy of 0.81 which is fairly good\n",
    "2. There is very less difference between train and test accuracy so its not overfitting or underfitting\n",
    "3. Recall is 0.79 which is not very good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1946c7f-5310-4698-ab6d-d227a4fe8e59",
   "metadata": {},
   "source": [
    "# Logistic Regression with Polynomial Features (degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "766c2ff6-c09b-4fa5-abbe-b0e8268e56ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>...</th>\n",
       "      <th>jun</th>\n",
       "      <th>mar</th>\n",
       "      <th>may</th>\n",
       "      <th>nov</th>\n",
       "      <th>oct</th>\n",
       "      <th>sep</th>\n",
       "      <th>failure</th>\n",
       "      <th>success</th>\n",
       "      <th>unknown</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>2476</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  balance  housing  loan  day  duration  campaign  pdays  \\\n",
       "0   59        1     2343        0     1    5      1042         1     -1   \n",
       "1   56        1       45        1     1    5      1467         1     -1   \n",
       "2   41        1     1270        0     1    5      1389         1     -1   \n",
       "3   55        1     2476        0     1    5       579         1     -1   \n",
       "4   54        1      184        1     1    5       673         2     -1   \n",
       "\n",
       "   previous  ...  jun  mar  may  nov  oct  sep  failure  success  unknown  \\\n",
       "0         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "1         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "2         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "3         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "4         0  ...    0    0    1    0    0    0        0        0        1   \n",
       "\n",
       "   deposit  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression with polynomial features works better with normalozation instead of standardization\n",
    "# so read file again\n",
    "\n",
    "df=pd.read_csv(\"PreprocessedBank.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "dfX=df.drop('deposit',axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d6727aa-7975-48b9-93a9-e8a56ef391ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>...</th>\n",
       "      <th>jul</th>\n",
       "      <th>jun</th>\n",
       "      <th>mar</th>\n",
       "      <th>may</th>\n",
       "      <th>nov</th>\n",
       "      <th>oct</th>\n",
       "      <th>sep</th>\n",
       "      <th>failure</th>\n",
       "      <th>success</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.532468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.268110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.078273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.377675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.298701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.092185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.357566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.480519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.148750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.079851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.172983</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  default   balance  housing  loan       day  duration  campaign  \\\n",
       "0  0.532468      1.0  0.104371      0.0   1.0  0.133333  0.268110  0.000000   \n",
       "1  0.493506      1.0  0.078273      1.0   1.0  0.133333  0.377675  0.000000   \n",
       "2  0.298701      1.0  0.092185      0.0   1.0  0.133333  0.357566  0.000000   \n",
       "3  0.480519      1.0  0.105882      0.0   1.0  0.133333  0.148750  0.000000   \n",
       "4  0.467532      1.0  0.079851      1.0   1.0  0.133333  0.172983  0.016129   \n",
       "\n",
       "   pdays  previous  ...  jul  jun  mar  may  nov  oct  sep  failure  success  \\\n",
       "0    0.0       0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0      0.0   \n",
       "1    0.0       0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0      0.0   \n",
       "2    0.0       0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0      0.0   \n",
       "3    0.0       0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0      0.0   \n",
       "4    0.0       0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0      0.0   \n",
       "\n",
       "   unknown  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minmaxscaler is used to normalise data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "bankMM = scaler.fit_transform(dfX)\n",
    "bankMM = pd.DataFrame(bankMM, columns=dfX.columns)\n",
    "bankMM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42ffe8b1-07ae-426e-bf6d-1b33e79d9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split (70:30)\n",
    "X_train,X_test,y_train,y_test=train_test_split(bankMM,df['deposit'],test_size=0.30, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52d4988c-349f-441c-971a-3697fd3e1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating polynomial features with degree 2\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X_trainP=poly2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe067927-c9cc-4153-90fd-fb8fc9e8d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "param_grid = {'penalty' : ['l1', 'l2'], 'C' : [0.001,0.01,0.1,1,5,25]    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2eda75c-53ad-4fec-93e9-cc8426af2d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#GridserchCV tries all possible combinations of hyperparameters to find best accuracy\n",
    "\n",
    "logModel = LogisticRegression()\n",
    "clf = GridSearchCV(logModel, param_grid = param_grid,scoring='accuracy',verbose=True, cv = 5,n_jobs=-1 )\n",
    "best_clf = clf.fit(X_trainP,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65dff70b-be9b-4765-b5a0-02882ba7ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create polynomial features with degree 2 for test data\n",
    "X_testP=poly2.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be6d6cdf-bdfd-421e-b455-7ffac4ff942f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1519  255]\n",
      " [ 266 1309]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      1774\n",
      "           1       0.84      0.83      0.83      1575\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "AUC score for LR Poly2 is  0.9071301515720908\n",
      "Test Accuracy score for LR Poly2 is  0.8444311734846223\n",
      "Train Accuracy score for LR Poly2 is  0.8681684372200179\n",
      "Best parameters for LR are  {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression with polynomial features with degree 2\n",
    "# Finding Accuracy, AUC, False positive rate, True positive rate, confusion matrix and classificatio report\n",
    "# get best parameters for retraining\n",
    "\n",
    "pred = best_clf.predict(X_testP)\n",
    "accLRP2 = accuracy_score(y_test, pred)\n",
    "y_pred_prob = best_clf.predict_proba(X_testP)\n",
    "aucScoreLRP2 = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprLRP2, tprLRP2, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"AUC score for LR Poly2 is \",aucScoreLRP2)\n",
    "print(\"Test Accuracy score for LR Poly2 is \",accLRP2)\n",
    "predT=best_clf.predict(X_trainP)\n",
    "print(\"Train Accuracy score for LR Poly2 is \",accuracy_score(y_train, predT))\n",
    "print(\"Best parameters for LR are \",best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9582e22-531b-4d75-a786-529b4f08e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logModel = LogisticRegression()\n",
    "clfR = GridSearchCV(logModel, param_grid = param_grid,scoring='recall',verbose=True, cv = 5,n_jobs=-1 )\n",
    "best_clfR = clfR.fit(X_trainP,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bacd2e56-3467-4766-aba8-c89491254775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall score for LR with polynomial features degree 2  is  0.8304761904761905\n",
      "Train recall score for LR with polynomial features degree 2 is  0.8651050080775444\n",
      "Best parameters for recall of LR with polynomial features degree 2 are  {'C': 5, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression for recall\n",
    "\n",
    "predR = best_clfR.predict(X_testP)\n",
    "predRT=best_clfR.predict(X_trainP)\n",
    "recallLRP2=recall_score(y_test, predR)\n",
    "print(\"Test Recall score for LR with polynomial features degree 2  is \",recallLRP2)\n",
    "print(\"Train recall score for LR with polynomial features degree 2 is \",recall_score(y_train, predRT))\n",
    "print(\"Best parameters for recall of LR with polynomial features degree 2 are \",best_clfR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ac3d8-89d0-469b-80e4-b6b63b318759",
   "metadata": {},
   "source": [
    "Notes:\n",
    "Logistic regression with polynomial features degree 2 gives accuracy of 0.84 which is quite good\n",
    "There is very less difference between train and test accuracy so its not overfitting or underfitting\n",
    "Recall is 0.83 which is quite good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e0444-1e3e-48b1-b26a-0d6f091a47ee",
   "metadata": {},
   "source": [
    "# Applying Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed345782-ecc5-4180-b216-a405ea4db586",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX=df.drop('deposit',axis=1)\n",
    "dfX.head()\n",
    "X_train,X_test,y_train,y_test=train_test_split(dfX,df['deposit'],test_size=0.30, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2931ec96-ffab-4474-a012-7989ac28eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "parameters={'max_depth':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "            'min_samples_leaf':[1,2,3,4,5],\n",
    "            'min_samples_split':[2,3,4,5],\n",
    "            'criterion':['gini','entropy']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "413da3f4-b22a-4067-872d-d46059f81d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(dt,parameters,scoring='accuracy',verbose=True)\n",
    "best_clf = clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "944a8efe-91ef-4744-98da-a30a9795b2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1385  389]\n",
      " [ 235 1340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82      1774\n",
      "           1       0.78      0.85      0.81      1575\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "AUC score for Decision Tree is  0.875908627261502\n",
      "Test Accuracy score for DT is  0.8136757240967453\n",
      "Train Accuracy score for DT is  0.8493536413669525\n",
      "Best parameters for DT are  {'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# Training Decision Tree\n",
    "# Finding Accuracy, AUC, False positive rate, True positive rate, confusion matrix and classificatio report\n",
    "# get best parameters for retraining\n",
    "\n",
    "pred = best_clf.predict(X_test)\n",
    "accDT = accuracy_score(y_test, pred)\n",
    "y_pred_prob = best_clf.predict_proba(X_test)\n",
    "aucScoreDT = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprDT, tprDT, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"AUC score for Decision Tree is \",aucScoreDT)\n",
    "print(\"Test Accuracy score for DT is \",accuracy_score(y_test, pred))\n",
    "predT=best_clf.predict(X_train)\n",
    "print(\"Train Accuracy score for DT is \",accuracy_score(y_train, predT))\n",
    "print(\"Best parameters for DT are \",best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba93c2a0-a260-4dac-b11e-90003db7b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv Training Decision Tree for recall\n",
    "\n",
    "clfR = GridSearchCV(dt,parameters,scoring='recall',verbose=True)\n",
    "best_clfR = clfR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e33bd79-34ea-4729-a2f3-6a5305df34ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1385  389]\n",
      " [ 235 1340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82      1774\n",
      "           1       0.78      0.85      0.81      1575\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "AUC score for Decision Tree is  0.875908627261502\n",
      "Test Accuracy score for DT is  0.8136757240967453\n",
      "Train Accuracy score for DT is  0.8493536413669525\n",
      "Best parameters for DT are  {'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# Training Decision Tree\n",
    "# Finding Accuracy, AUC, False positive rate, True positive rate, confusion matrix and classificatio report\n",
    "# get best parameters for retraining\n",
    "\n",
    "pred = best_clf.predict(X_test)\n",
    "accDT = accuracy_score(y_test, pred)\n",
    "y_pred_prob = best_clf.predict_proba(X_test)\n",
    "aucScoreDT = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprDT, tprDT, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"AUC score for Decision Tree is \",aucScoreDT)\n",
    "print(\"Test Accuracy score for DT is \",accuracy_score(y_test, pred))\n",
    "predT=best_clf.predict(X_train)\n",
    "print(\"Train Accuracy score for DT is \",accuracy_score(y_train, predT))\n",
    "print(\"Best parameters for DT are \",best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1329e2e5-fd7b-4faf-87be-95ea88af3f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv Training Decision Tree for recall\n",
    "\n",
    "clfR = GridSearchCV(dt,parameters,scoring='recall',verbose=True)\n",
    "best_clfR = clfR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65818d72-d7ec-4364-bc22-d8b68972d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall score for DT is  0.8253968253968254\n",
      "Train recall score for DT is  0.8309100700053851\n",
      "Best parameters for recall of DT are  {'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "predR = best_clfR.predict(X_test)\n",
    "predRT=best_clfR.predict(X_train)\n",
    "recallDT=recall_score(y_test, predR)\n",
    "print(\"Test Recall score for DT is \",recallDT)\n",
    "print(\"Train recall score for DT is \",recall_score(y_train, predRT))\n",
    "print(\"Best parameters for recall of DT are \",best_clfR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768b3f3-63f4-4b5f-84d0-3206fe76a4ef",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Decision Tree gives accuracy of 0.81 which is quite good\n",
    "There is very less difference between train and test accuracy so its not overfitting or underfitting\n",
    "Recall is 0.82 which is quite good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6561cf40-9682-4996-9bd8-06698f897b3b",
   "metadata": {},
   "source": [
    "# Applying XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fbb83-d914-45fe-a886-ef393903899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            'eta': np.arange(0.1, 0.26, 0.05),\n",
    "            'min_child_weight': np.arange(1, 5, 0.5).tolist(),\n",
    "            'gamma': [5],\n",
    "            'subsample': np.arange(0.5, 1.0, 0.11).tolist(),\n",
    "            'colsample_bytree': np.arange(0.5, 1.0, 0.11).tolist()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb3b94-83c2-45cd-848e-7e56b31222b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(objective = \"binary:logistic\")\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = True)\n",
    "clf = GridSearchCV(xgb_model, param_grid = params, scoring = 'accuracy',cv = skf.split(X_train, y_train),verbose=True)\n",
    "best_clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839785f-0306-44b7-b847-95153bd6dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training XGBOOST\n",
    "# Finding Accuracy, AUC, False positive rate, True positive rate, confusion matrix and classificatio report\n",
    "# get best parameters for retraining\n",
    "\n",
    "pred = best_clf.predict(X_test)\n",
    "accXGBOOST = accuracy_score(y_test, pred)\n",
    "y_pred_prob = best_clf.predict_proba(X_test)\n",
    "aucScoreXGBOOST = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprXGBOOST, tprXGBOOST, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"AUC score for XGBOOST is \",aucScoreXGBOOST)\n",
    "print(\"Test Accuracy score for XGBOOST is \",accuracy_score(y_test, pred))\n",
    "predT=best_clf.predict(X_train)\n",
    "print(\"Train Accuracy score for XGBOOST is \",accuracy_score(y_train, predT))\n",
    "print(\"Best parameters for XGBOOST are \",best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7309c033-47ff-4b99-befb-ff17faa79764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 800 candidates, totalling 8000 fits\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv And Training XGBBOST for recall\n",
    "clfR = GridSearchCV(xgb_model, param_grid = params, scoring = 'recall',cv = skf.split(X_train, y_train),verbose=True)\n",
    "best_clfR = clfR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7d0820aa-a969-4236-97f8-b7432690413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall score for XGBOOST is  0.8704761904761905\n",
      "Train recall score for XGBOOST is  0.8933764135702746\n",
      "Best parameters for recall of XGBOOST are  {'colsample_bytree': 0.83, 'eta': 0.20000000000000004, 'gamma': 5, 'min_child_weight': 1.0, 'subsample': 0.94}\n"
     ]
    }
   ],
   "source": [
    "predR = best_clfR.predict(X_test)\n",
    "predRT=best_clfR.predict(X_train)\n",
    "recallXGBOOST=recall_score(y_test, predR)\n",
    "print(\"Test Recall score for XGBOOST is \",recallXGBOOST)\n",
    "print(\"Train recall score for XGBOOST is \",recall_score(y_train, predRT))\n",
    "print(\"Best parameters for recall of XGBOOST are \",best_clfR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4a803-5b2b-4cad-a2f4-56e88cb7a304",
   "metadata": {},
   "source": [
    "XGBOOST gives accuracy of 0.85 which is best amongst them\n",
    "There is very less difference between train and test accuracy so its not overfitting or underfitting\n",
    "Recall is 0.88 which is really Good\n",
    "XGBBOST is basically an implementation of GBDT Gradint Boosting Decision Tree\n",
    "XGBOOST have given us the best result so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a8d1a-ec73-44e4-af5e-a72b019ad44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes:\n",
    "\n",
    "XGBOOST gives accuracy of 0.85 which is best amongst them\n",
    "There is very less difference between train and test accuracy so its not overfitting or underfitting\n",
    "Recall is 0.88 which is really Good\n",
    "XGBBOST is basically an implementation of GBDT Gradint Boosting Decision Tree\n",
    "XGBOOST have given us the best result so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c793f-51ba-4593-acc2-a875d3abe1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
